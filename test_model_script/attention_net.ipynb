{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bba84cf-ae23-4d40-a0d0-98db30c66d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:02:39.217411: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-07 05:02:39.217456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-07 05:02:39.219023: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-07 05:02:39.228449: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "set_seed(42)  # Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd680647-2530-492e-89d1-1013de6c8f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def attention_block(x, g, inter_channel):\n",
    "    theta_x = layers.Conv2D(inter_channel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    phi_g = layers.Conv2D(inter_channel, (1, 1), strides=(1, 1), padding='same')(g)\n",
    "    add_xg = layers.add([theta_x, phi_g])\n",
    "    act_xg = layers.Activation('relu')(add_xg)\n",
    "    psi = layers.Conv2D(1, (1, 1), strides=(1, 1), padding='same')(act_xg)\n",
    "    psi = layers.Activation('sigmoid')(psi)\n",
    "    upsample_psi = layers.UpSampling2D(size=(x.shape[1] // psi.shape[1], x.shape[2] // psi.shape[2]))(psi)\n",
    "    attn = layers.multiply([upsample_psi, x])\n",
    "    return attn\n",
    "\n",
    "def attention_unet(input_shape=(224, 224, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Contracting Path\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Expansive Path with Attention\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    att6 = attention_block(c4, u6, 512)\n",
    "    u6 = layers.concatenate([u6, att6])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    att7 = attention_block(c3, u7, 256)\n",
    "    u7 = layers.concatenate([u7, att7])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    att8 = attention_block(c2, u8, 128)\n",
    "    u8 = layers.concatenate([u8, att8])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    att9 = attention_block(c1, u9, 64)\n",
    "    u9 = layers.concatenate([u9, att9])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6cc17-a8b1-47bb-b38b-27c727f87661",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 224, 224, 64)         1792      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 224, 224, 64)         36928     ['conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 112, 112, 64)         0         ['conv2d_32[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 112, 112, 128)        73856     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 112, 112, 128)        147584    ['conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 56, 56, 128)          0         ['conv2d_34[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 56, 56, 256)          295168    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 56, 56, 256)          590080    ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 28, 28, 256)          0         ['conv2d_36[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 28, 28, 512)          1180160   ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 28, 28, 512)          2359808   ['conv2d_37[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 14, 14, 512)          0         ['conv2d_38[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 14, 14, 1024)         4719616   ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 14, 14, 1024)         9438208   ['conv2d_39[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2D  (None, 28, 28, 512)          2097664   ['conv2d_40[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 28, 28, 512)          262656    ['conv2d_38[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 28, 28, 512)          262656    ['conv2d_transpose_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 28, 28, 512)          0         ['conv2d_41[0][0]',           \n",
      "                                                                     'conv2d_42[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 28, 28, 512)          0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 28, 28, 1)            513       ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 28, 28, 1)            0         ['conv2d_43[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 28, 28, 1)            0         ['activation_9[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)       (None, 28, 28, 512)          0         ['up_sampling2d_4[0][0]',     \n",
      "                                                                     'conv2d_38[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 28, 28, 1024)         0         ['conv2d_transpose_4[0][0]',  \n",
      " )                                                                   'multiply_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 28, 28, 512)          4719104   ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 28, 28, 512)          2359808   ['conv2d_44[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2D  (None, 56, 56, 256)          524544    ['conv2d_45[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 56, 56, 256)          65792     ['conv2d_36[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 56, 56, 256)          65792     ['conv2d_transpose_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 56, 56, 256)          0         ['conv2d_46[0][0]',           \n",
      "                                                                     'conv2d_47[0][0]']           \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 56, 56, 256)          0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, 56, 56, 1)            257       ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 56, 56, 1)            0         ['conv2d_48[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 56, 56, 1)            0         ['activation_11[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)       (None, 56, 56, 256)          0         ['up_sampling2d_5[0][0]',     \n",
      "                                                                     'conv2d_36[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 56, 56, 512)          0         ['conv2d_transpose_5[0][0]',  \n",
      " )                                                                   'multiply_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (None, 56, 56, 256)          1179904   ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (None, 56, 56, 256)          590080    ['conv2d_49[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2D  (None, 112, 112, 128)        131200    ['conv2d_50[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (None, 112, 112, 128)        16512     ['conv2d_34[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (None, 112, 112, 128)        16512     ['conv2d_transpose_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 112, 112, 128)        0         ['conv2d_51[0][0]',           \n",
      "                                                                     'conv2d_52[0][0]']           \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 112, 112, 128)        0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (None, 112, 112, 1)          129       ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 112, 112, 1)          0         ['conv2d_53[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, 112, 112, 1)          0         ['activation_13[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)       (None, 112, 112, 128)        0         ['up_sampling2d_6[0][0]',     \n",
      "                                                                     'conv2d_34[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 112, 112, 256)        0         ['conv2d_transpose_6[0][0]',  \n",
      " )                                                                   'multiply_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (None, 112, 112, 128)        295040    ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (None, 112, 112, 128)        147584    ['conv2d_54[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2D  (None, 224, 224, 64)         32832     ['conv2d_55[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (None, 224, 224, 64)         4160      ['conv2d_32[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)          (None, 224, 224, 64)         4160      ['conv2d_transpose_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 224, 224, 64)         0         ['conv2d_56[0][0]',           \n",
      "                                                                     'conv2d_57[0][0]']           \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 224, 224, 64)         0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)          (None, 224, 224, 1)          65        ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 224, 224, 1)          0         ['conv2d_58[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSamplin  (None, 224, 224, 1)          0         ['activation_15[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)       (None, 224, 224, 64)         0         ['up_sampling2d_7[0][0]',     \n",
      "                                                                     'conv2d_32[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 224, 224, 128)        0         ['conv2d_transpose_7[0][0]',  \n",
      " )                                                                   'multiply_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)          (None, 224, 224, 64)         73792     ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, 224, 224, 64)         36928     ['conv2d_59[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, 224, 224, 1)          65        ['conv2d_60[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31730949 (121.04 MB)\n",
      "Trainable params: 31730949 (121.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = attention_unet(input_shape=(224, 224, 3))\n",
    "\n",
    "# Compile the model with Adam optimizer (with momentum via beta_1)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c01c6b1-841f-4d4c-b7eb-37ea9906a11d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2975, 224, 224, 3), (2975, 224, 224, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_images = np.load(\"../../numpy_arr_data/train_img_224.npy\")\n",
    "train_masks = np.load(\"../../numpy_arr_data/train_mask_224.npy\")\n",
    "\n",
    "train_images.shape, train_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fdf1832-b342-4472-afcd-3b1197762ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5735"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1b1df-592d-42e2-9d1e-aeb095d279a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:05:06.364759: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-09-07 05:05:34.320748: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc410ce69e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-07 05:05:34.320790: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-09-07 05:05:34.328661: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725685534.440712  164513 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-09-07 05:05:39.899873: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-09-07 05:05:39.899944: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-09-07 05:05:41.567495: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-09-07 05:05:41.567564: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 231s 2s/step - loss: 0.4708 - accuracy: 0.8520 - val_loss: 0.2846 - val_accuracy: 0.8666 - lr: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:08:53.386436: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/75 [>.............................] - ETA: 1:31 - loss: 0.2911 - accuracy: 0.8684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:08:58.614289: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/75 [=>............................] - ETA: 1:29 - loss: 0.2823 - accuracy: 0.8733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:09:01.274226: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/75 [==>...........................] - ETA: 1:26 - loss: 0.2833 - accuracy: 0.8711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:09:05.213301: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/75 [===>..........................] - ETA: 1:22 - loss: 0.2823 - accuracy: 0.8697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:09:09.146104: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/75 [====>.........................] - ETA: 1:19 - loss: 0.2805 - accuracy: 0.8711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 05:09:11.803505: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/75 [============>.................] - ETA: 55s - loss: 0.2743 - accuracy: 0.8719"
     ]
    }
   ],
   "source": [
    "# Clear the session to avoid any potential issues with model state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train with ReduceLROnPlateau callback\n",
    "history = model.fit(train_images, train_masks, epochs=50, batch_size=32, validation_split=0.2, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ee92f-d066-4a9f-8f24-75d96bf0079c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('../model/attention_u_net_model/aunet_dynamic_original.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c20613c9-d1af-42de-a1f9-5d513e4a70e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb7d4d-75c5-45dc-9b6e-85524772854d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
